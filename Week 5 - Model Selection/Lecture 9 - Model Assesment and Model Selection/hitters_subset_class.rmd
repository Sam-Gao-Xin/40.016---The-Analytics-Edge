---
title: "Hitters Notebook"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---

The hitters dataset consists of 322 observations of 21 variables with the following information - X (name), AtBat, Hits, HmRun (home runs), Runs, RBI, Walks, Years, CAtBat, CHits, CHmRun, CRuns, CRBI, CWalks, League, Division, PutOuts, Assists, Errors, Salary, New League. Here League, Division and NewLeagues are factor variabes with 2 categories. We drop rows with missing entries and are left with 263 observations.
```{r}
setwd("/Users/james/OneDrive - Singapore University of Technology and Design/SUTD/Year 3/Term 6/40.016 - The Analytics Edge/Week 5/Lecture 9 - Model Assesment and Model Selection")
rm(list=ls())
hitter <- read.csv("Hitters(9).csv")
str(hitter)
hitters<-na.omit(hitter)
str(hitters)
```
The leaps package in R does subset selection with the regsubsets function. By default, the maximum number of subsets, this function uses is 8. We extend this to do a complete subset selection by changing the default value of nvmax argument in this function. Note that CRBI is in the model with 1 to 6 variables but not in the model with 7 and 8 variables.
```{r}
install.packages("leaps")
library(leaps)
?regsubsets
hitters <- hitter[,2:21]
model1 <- regsubsets(Salary~.,hitters)
summary(model1)
model2 <- regsubsets(Salary~., hitters, nvmax=19) #Changing the max number of features in the model, and value for 19 for all the feature variables, as the default value of nvmax is 8
summary(model2)

plot(model2)
#
#
```
```{r}
names(summary(model2))
summary(model2)$rsq
plot(summary(model2)$rsq)
plot(summary(model2)$rss)
plot(summary(model2)$adjr2)
which.max(summary(model2)$adjr2)
coef(model2,11)
```
The figures indicate that R-squared increase as the number of variables in the subset increases and likewise the residual sum of squared (sum of squared errors) decreases as the size of the subsets increases. On the other hand the adjusted R-squared increases first and then decreases.

Forward stepwise selection: In this example, the best model identified by the forward stepwise selection is the same as that obtained by the best subset selection. It is also possible to run this algorithm using a backward method where you drop variables one a time rather add. In general, the solutions from these two methods can be different.
```{r}
model3<-regsubsets(Salary~.,data=hitters,nvmax=19,method="forward")
which.max(summary(model3)$adjr2)
coef(model3,11)
summary(model2)$adjr2-summary(model3)$adjr2
plot(summary(model3)$adjr2)
summary(model3)

model4<-regsubsets(Salary~.,data=hitters,nvmax=19,method="backward")
which.max(summary(model4)$adjr2)
coef(model4,11)
summary(model4)

#This will gives us the best permutation for n number of variables, say if we only want 3 predictor variables, it'll place the * for the best permutation of predictor variables combination
```


