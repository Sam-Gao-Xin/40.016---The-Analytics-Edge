rm(list=ls()) # Clear the environment
setwd("/Users/james/OneDrive - Singapore University of Technology and Design/SUTD/Year 3/Term 6/40.016 - The Analytics Edge/Week 10 - Text Analytics and Naive Bayes Classifier/Lecture 17 - Text Analytics(Part II)")  # Setup the working directory
energy <- read.csv("energy_bid(1).csv",stringsAsFactors=FALSE)
energy <- read.csv("energy_bid(1).csv",stringsAsFactors=FALSE)
str(energy)
energy$email[1] # list out the entire email (but this is hard to read).
# ?strwrap
strwrap(energy$email[1])
energy$responsive[1] # This takes value 0 since the email is not responsive to energy bid and schedule.
# ?strwrap
strwrap(energy$email[1])
energy$responsive[1] # This takes value 0 since the email is not responsive to energy bid and schedule.
energy$email[2] # list out the entire email (but this is hard to read).
energy$email[1] # list out the entire email (but this is hard to read).
# ?strwrap
strwrap(energy$email[1])
strwrap(energy$email[4])
energy$responsive[4] # The fourth email deals with the search on the energy bids and schedules. hence, the responsive variable takes a value of 1.
table(energy$responsive)
if(!require(tm)){
install.packages("tm")
library(tm)
}
if(!require(SnowballC)){
install.packages("SnowballC")
library(SnowballC)
}
corpus <- Corpus(VectorSource(energy$email))
as.character(corpus[[4]]) # We check the fourth entry
strwrap(as.character(corpus[[4]])) # Read the email in the corpus
corpus <- tm_map(corpus,content_transformer(tolower))
corpus <- tm_map(corpus,removeWords,stopwords("english"))
corpus <- tm_map(corpus,removePunctuation)
corpus <- tm_map(corpus,removeNumbers)
corpus <- tm_map(corpus,stemDocument)
strwrap(energy$email[4])
strwrap(as.character(corpus[[4]]))
strwrap(energy$email[4])
strwrap(as.character(corpus[[4]]))
dtm <- DocumentTermMatrix(corpus)
dtm
inspect(dtm[4,])
dtm <- removeSparseTerms(dtm,0.97)
dtm
energysparse <- as.data.frame(as.matrix(dtm))
colnames(energysparse) <- make.names(colnames(energysparse))
# str(energysparse)
str(energysparse)
# Load the wordcloud package
if(!require(wordcloud)){
install.packages("wordcloud")
library(wordcloud)
}
# Get word counts in decreasing order
word_freqs = sort(colSums(energysparse), decreasing=TRUE)
# Create data frame with words and their frequencies
dm = data.frame(word=names(word_freqs), freq=unname(word_freqs))
# Plot wordcloud (we limit the plot to 100 words)
wordcloud(dm$word, dm$freq, random.order=FALSE, colors=brewer.pal(8, "Dark2"), max.words=100)
energysparse$responsive <- energy$responsive
# Load the caTools package and set the seed
if(!require(caTools)){
install.packages("caTools")
library(caTools)
}
set.seed(123)
# Create train and test sets (with balanced response)
spl   <- sample.split(energysparse$responsive,SplitRatio=0.7)
train <- subset(energysparse,spl==TRUE)
test  <- subset(energysparse,spl==FALSE)
library(rpart)
model1 <- rpart(as.factor(responsive)~.,data=train)
library(rpart.plot)
prp(model1,type=4,extra=2)
predict1 <- predict(model1,newdata=test,type="class")
table(predict1,test$responsive)
printcp(model1)
library(randomForest)
model2 <- randomForest(as.factor(responsive)~.,data=train)
model2
# summary(model2)
varImpPlot(model2)
predict2 <- predict(model2,newdata=test,type="class")
table(predict2,test$responsive)
# ?varUsed
# varUsed(model2)
order2 <- sort(varUsed(model2), decreasing=TRUE, index.return=TRUE) # Return sorted frequency and indices
# head(order2$ix)
names(test[,head(order2$ix)]) # we can see which words are important!
library(ROCR)
predictprob1 <- predict(model1,newdata=test,type="prob")
predictprob2 <- predict(model2,newdata=test,type="prob")
pred1 <- prediction(predictprob1[,2],test$responsive)
pred2 <- prediction(predictprob2[,2],test$responsive)
# performance(pred1,measure="auc")
# performance(pred2,measure="auc")
if(!require(e1071)){
install.packages("e1071")
library(e1071)
}
model3 <- naiveBayes(as.factor(responsive)~.,data=train)
# summary(model3)
model3$apriori
model3$tables$california
model3$tables$market
