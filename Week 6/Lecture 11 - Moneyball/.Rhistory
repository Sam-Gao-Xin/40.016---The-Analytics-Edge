baseball <- read.csv("baseball.csv")
setwd("/Users/james/OneDrive - Singapore University of Technology and Design/SUTD/Year 3/Term 6/40.016 - The Analytics Edge/Week 6/Lecture 11 - Moneyball")
ggplot(baseball2002, aes(RD, W)) + geom_point() +geom_smooth(method="lm")
baseball2002$RD = baseball2002$RS - baseball2002$RA
model1 <- lm(W~RD, baseball2002)
m5$coefficients[1]+m5$coeffcieints[2]*0.339 + m5$coefficients[3]*0.43
setwd("/Users/james/OneDrive - Singapore University of Technology and Design/SUTD/Year 3/Term 6/40.016 - The Analytics Edge/Week 6/Lecture 11 - Moneyball")
Songs <- read.csv("songs.csv")
Songs <- read.csv("songs(7).csv")
str(Songs)
table(Songs$artistname == "Micheal Jackson")
table(Songs$artistname == "Micheal Jackson")
setwd("/Users/james/OneDrive - Singapore University of Technology and Design/SUTD/Year 3/Term 6/40.016 - The Analytics Edge/Week 6/Lecture 11 - Moneyball")
Songs <- read.csv("songs(7).csv")
Songs <- read.csv("songs(7).csv")
str(Songs)
head(Songs)
table(Songs$artistname == "Micheal Jackson")
SongsTrain <- Songs[Songs$year <= 2009,]
SongsTest <- Songs[Songs$year -= 2010,]
SongsTrain <- Songs[Songs$year <= 2009,]
SongsTest <- Songs[Songs$year == 2010,]
nonvars = c("year", "songtitle","artistname", "songID", "artistID")
SongLogs1 = glm(Top10~. , data=SongsTrain, famiily=bonomial)
SongLogs1 = glm(Top10~. , data=SongsTrain, famiily=binomial)
SongLogs1 = glm(formula = Top10~. , data=SongsTrain, famiily=binomial)
#To remove these variables from your training and testing sets, use the neat command
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
#To remove these variables from your training and testing sets, use the neat command
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
#To remove these variables from your training and testing sets, use the neat command
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
SongLogs1 = glm(Top10~ . , data=SongsTrain, famiily=binomial)
SongLogs1 = glm(Top10~ . , data=SongsTrain, family=binomial)
summary(SongLogs1)
predict(SongLogs1)
sum(summary(SongsLog1)$coefficients[2:34, 4] < 0.05)
sum(summary(SongsLog1)$coefficients[2:34, 4] < 0.05)
SongsLogs1 = glm(Top10~ . , data=SongsTrain, family=binomial)
summary(SongLogs1)
sum(summary(SongsLogs1)$coefficients[2:34, 4] < 0.05)
predict_test <- predict(SongsLogs1, newdata=SongsTest, type="response")
CM
CM <- table(predict_test>0.45, SongsTest$Top10)
CM
(309+15)/(309+44+5+15)
predict_test
summary(predict_test)
CM
predict_fy <- predict(SongsLogs1, newdata = fixyou, type="reponse")
predict_fy <- predict(SongsLogs1, newdata = fixyou, type="response")
fixyou = Songs[Songs$songtitle == "Fix You"]
predict_fy <- predict(SongsLogs1, newdata = fixyou, type="response")
fixyou = Songs[Songs$songtitle == "Fix You",]
predict_fy <- predict(SongsLogs1, newdata = fixyou, type="response")
fixyou = Songs[Songs$songtitle == "Fix You",]
predict_fy <- predict(SongsLogs1, newdata = fixyou, type="response")
Solve for how many units of increase in loudness we need to add to the song, to get the probability to 0.20 using this model.
```{r}
prob = unname(predict_fy)
```
Suppose we miraculously found ways to change the song such that we can change values of any columns without affecting the other columns. Using this technique, we want to increase the chance that "Fix You" is a hit song. We decreased the energy by 0.2 units and increased the loudness by 2 units. What is the new probability of "Fix You" being a Top Hit?
```{r}
predict_fy
prob = unname(predict_fy)
prob
(logodds2 - logodds)/0.2999
logodds2 = log(0.2/(1-0.2))
logodds2
(logodds2 - logodds)/0.2999
logodds = log(prob/(1-prob))
logodds
logodds2 = log(0.2/(1-0.2))
logodds2
prob
siglist = summary(SongsLogs1$coefficients[summary(SongLogs1)$coefficients[,4]<0.05, 4])
siglist = summary(SongsLogs1$coefficients[summary(SongLogs1)$coefficients[,4]<0.05, 4]
siglist
siglist
siglist = summary(SongsLogs1$coefficients[summary(SongLogs1)$coefficients[,4]<0.05, 4]
siglist = summary(SongsLogs1)$coefficients[summary(SongLogs1)$coefficients[,4]<0.05, 4]
siglist
siglist = summary(SongsLogs1)$coefficients[summary(SongLogs1)$coefficients[,4]<0.05, 4]
siglist
sigformula
sigpred = names(siglist[2:length(siglist)])
sigformula = as.formula(paste0("Top10 ~ ", paste0(sigpred, collapse = " + ")))
sigformula
SongLogs2 = glm(sigformula, data=SongsTrain, family=binomial)
setwd("/Users/james/OneDrive - Singapore University of Technology and Design/SUTD/Year 3/Term 6/40.016 - The Analytics Edge/Exercise/Week 2")
auto<-read.csv("Auto(3).csv")
str(auto)
auto$horsepower <- as.numeric(as.character(auto$horsepower))
model1<- lm(mpg~horsepower, data=auto)
summary(model1)
cor(x1,x2)
set.seed(1)
x1 <- runif(100)
x2 <- 0.5*x1 + rnorm(100)/10
y <- 2 + 2*x1 + 0.3*x2 + rnorm(100)
cor(x1,x2)
ggplot(cbind(x1,x2,y),aes(x1,x2))+geom_point()
library(ggplot2)
ggplot(cbind(x1,x2,y),aes(x1,x2))+geom_point()
ggplot2(cbind(x1,x2,y),aes(x1,x2))+geom_point()
ggplot(cbind(x1,x2,y),aes(x1,x2))+geom_point()
fortify(cbind(x1,x2,y),aes(x1,x2))+geom_point()
model3 <- lm(y~x1+x2)
summary(model3)
model4 <- lm(y~x1)
summary(model4)
model5 <- lm(y~x2)
summary(model5)
boston <- read.csv("Boston(4).csv")
colnames(boston)
model1 <- lm(medv~crim, data=boston)
model2 <- lm(medv~zn, data=boston)
model3 <- lm(medv~indus, data=boston)
model4 <- lm(medv~chas, data=boston)
model5 <- lm(medv~nox, data=boston)
model6 <- lm(medv~rm, data=boston)
model7 <- lm(medv~age, data=boston)
model8 <- lm(medv~dis, data=boston)
model9 <- lm(medv~rad, data=boston)
model10 <- lm(medv~tax, data=boston)
model11 <- lm(medv~ptratio, data=boston)
model12 <- lm(medv~black, data=boston)
model13 <- lm(medv~lstat, data=boston)
summary(model1)
summary(model13)
ggplot(boston,aes(lstat,medv))+geom_point(na.rm=T)+geom_smooth(method="lm",na.rm=T,se=F)
modelall<- lm(medv~., data=boston)
summary(modelall)
summary(model1)
ggplot(boston,aes(lstat,medv))+geom_point(na.rm=T)+geom_smooth(method="lm",na.rm=T,se=F)
model1$coef[0]
model1$coef[1]
model1$coef[2]
All
Ind
Ind <- c(model1$coef[2], model2$coef[2], model3$coef[2], model4$coef[2], model5$coef[2],
model6$coef[2], model7$coef[2], model8$coef[2], model9$coef[2], model10$coef[2],
model11$coef[2], model12$coef[2], model13$coef[2])
Ind
All <- modelall$coef[2:14]
All
ggplot(cbind(Ind,All),aes(Ind,All)) + geom_point()+geom_smooth(method="lm",se=F)+ggtitle("Coefficient relationship") + xlab("Simple linear regression") + ylab("Multiple linear regression")
Ind <- c(model1$coef[2], model2$coef[2], model3$coef[2], model4$coef[2], model5$coef[2],
model6$coef[2], model7$coef[2], model8$coef[2], model9$coef[2], model10$coef[2],
model11$coef[2], model12$coef[2], model13$coef[2])
Ind
All <- modelall$coef[2:14]
All
ggplot(cbind(Ind,All),aes(Ind,All)) + geom_point()+geom_smooth(method="lm",se=F)+ggtitle("Coefficient relationship") + xlab("Simple linear regression") + ylab("Multiple linear regression")
summary(model13)
modelpoly2 <- lm(medv~poly(lstat,2,raw=TRUE), data = boston)
summary(modelpoly2)
modelpoly3 <- lm(medv~poly(lstat,3,raw=TRUE), data = boston)
summary(modelpoly3)
modelpoly4 <- lm(medv~poly(lstat,4,raw=TRUE), data = boston)
summary(modelpoly4)
modelpoly5 <- lm(medv~poly(lstat,5,raw=TRUE), data = boston)
summary(modelpoly5)
modelpoly6 <- lm(medv~poly(lstat,6,raw=TRUE), data = boston)
summary(modelpoly6)
boston$pr1 <- predict(model13,newdata=boston)
boston$pr5 <- predict(modelpoly5,newdata=boston)
ggplot(boston)+geom_point(aes(lstat,medv))+geom_line(aes(lstat,pr1),color="blue",size=2)+geom_line(aes(lstat,pr5),color="red",linetype="solid",size=2)
boston$pr1 <- predict(model13,newdata=boston)
boston$pr5 <- predict(modelpoly5,newdata=boston)
ggplot(boston)+geom_point(aes(lstat,medv))+geom_line(aes(lstat,pr1),color="blue",size=2)+geom_line(aes(lstat,pr5),color="red",linetype="solid",size=2)
cor(x1,x2)
library(ggplot2)
ggplot(cbind(x1,x2,y),aes(x1,x2))+geom_point()
wine<-read.csv("winedata(3).csv")
str(wine)
wine$age91<-1991-wine$vintage
str(wine)
wine$age91<-1991-wine$vintage
wine$age91<-1991-wine$vintage
wine$age91<-1991-wine$vintage
wine$age92<-1992-wine$vintage
mean(subset(wine$price91,wine$age91>=15))
str(wine)
train<-subset(wine,vintage<=1981)
model1<-lm(log(price91)~age91,data=train)
summary(model1)
confint(model1, level = 0.99)
test<-subset(wine,vintage>=1982)
predtest<-predict(model1,newdata=test)
sse<-sum((log(test$price91)-predtest)^2)
sst<-sum((log(test$price91)-mean(log(train$price91)))^2)
testR2<- 1-sse/sst
testR2
model2<-lm(log(price91)~temp+hrain+wrain+tempdiff+age91,data=train)
summary(model2)
summary(model2)
model3<-lm(log(price91)~age91,data=train)
summary(model3)
model2a<-lm(log(price91)~age91,data=train)
model2<-lm(log(price91)~temp+hrain+wrain+tempdiff+age91,data=train)
summary(model2)
model3<-lm(log(price91)~temp+hrain+age91,data=train)
summary(model3)
model4<-lm(log(price92)~temp+hrain+age92,data=train)
summary(model4)
nrows(iris)
nrows(iris)
library(dplr)
nrow(iris)
```{r}
nrow(iris)
dim(iris)
ncol(iris)
str(iris)
colnames(iris)
head(iris)
iris.data<-iris[,-5]
iris.data
iris
iris.data
iris.data<-iris[,-5]
iris.sp<-iris[,5]
iris.sp
library(psych)
pairs.panels(iris.data, ellipses = F, lm =T, breaks=10, hist.col="blue")
pr.out<-prcomp(iris.data,scale=F)
summary(pr.out)
pr.out$sdev
summary(pr.out)
pr.out<-prcomp(iris.data,scale=F)
summary(pr.out)
pr.out$sdev
summary(pr.out)
#2.9 Principal Component Analysis(PCA)
pca_output <- prcomp(df,scale=T)
summary(pca_output)
pr.out$sdev
summary(pr.out)
pve<-pr.out$sdev^2/sum(pr.out$sdev^2)
cpve<-cumsum(pve)
pve
pr.out
summary(pr.out)
summary(pr.out)[1]
summary(pr.out)[2]
summary(pr.out)[0]
summary(pr.out)
cpve<-cumsum(pve)
pve
cpve
plot(cpve,xlab="Principal components",type="l",ylim=c(0.7,1))
hist(cpve,xlab="Principal components",type="l",ylim=c(0.7,1))
plot(cpve,xlab="Principal components",type="l",ylim=c(0.7,1))
library(factoextra)
fviz_pca_biplot(pr.out, label = "var", habillage=iris.sp)
library(factoextra)
install.packages("factoextra")
library(factoextra)
install.packages(factoextra)
install.package(factoextra)
install.packages(factoextra)
install.packages("factoextra")
library(factoextra)
remove.packages("factoextra")
install.packages("factoextra")
fviz_pca_biplot(pr.out, label = "var", habillage=iris.sp)
fviz_pca_biplot(pr.out, label = "var", habillage=iris.sp)
library(factoextra)
install.packages("factoextra")
library(factoextra)
19
8
I keep getting the following error when attempting to install readxl or haven in R (both dependencies of tidyverse) post-compilation, when the installer runs the loading test:
** testing if installed package can be loaded
Error in dyn.load(file, DLLpath = DLLpath, ...) :
unable to load shared object '<my_lib_Path>/readxl/libs/readxl.so':
<my_lib_path>/readxl/libs/readxl.so: undefined symbol: libiconv
Error loading failed
I have libiconv.so in a local lib path (not for R packages) that is included in LD_LIBRARY_PATH and I've verified in my R session that Sys.getenv("LD_LIBRARY_PATH") has that directory. Why can't R's dynamic library loader find this shared object? Is there a different R-specific environment variable I need to define to have the dynamic library loader in R search my local lib path?
Please note that this is not an issue with an R library path, but instead for a non-R dependency that an R package has. If I were compiling and linking C++ code, gcc would use ld, and hence LD_LIBRARY_PATH to track down dynamic dependencies. R doesn't appear to respect this rather common approach, and I can't seem to find any documentation on how to manage these more fine-grained dependency issues.
Additional Details
!> sessionInfo()
R version 3.3.3 (2017-03-06)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)
locale:
[1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
[3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
[5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
[7] LC_PAPER=en_US.UTF-8       LC_NAME=C
[9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
>
I had previously compiled libiconv because it was a dependency for something else (don't recall what now - likely not an R package given current problems). I tried reinstalling it, but made no difference.
Edit
I have also tried manually loading the library prior to installation:
> dyn.load(".local/lib/libiconv.so")
> is.loaded("libiconv")
[1] TRUE
> install.packages("tidyverse")
but it fails just as above.
r
dynamic-loading
install.packages
share  edit  follow
edited Jul 16 '17 at 17:49
asked Jul 14 '17 at 22:36
merv
36.6k77 gold badges105105 silver badges149149 bronze badges
Have you tried deleting readxl or haven from the /library/ folder and re-installing? – Mako212 Jul 14 '17 at 22:50
I am not sure if this is helpful, but perhaps you should check the output of .libPaths()? You can also use it to "gets/sets the library trees within which packages are looked for." – student Jul 15 '17 at 4:48
@Mako212 By default, R cleans up (deletes) libraries that fail to fully install, so invoking install.packages("tidyverse") always attempts to install readxl and haven afresh. – merv Jul 15 '17 at 5:45
1
What's the output of ldd /<my_lib_path>/readxl/libs/readxl.so , executed from within R ? Maybe that's informative. – knb Jul 16 '17 at 21:25
1
@merv glad to hear that. I've often relied on ldd to check installation/loading problems. Often it's not directly helpful, but "indirectly". – knb Jul 19 '17 at 6:54
show 3 more comments
5 Answers
11
Normally, the iconv method is picked up from glibc, which is linked to during build of the R packages in question. For whatever reason, however, iconv is getting resolved to libiconv in this case, but it is not linked by the R packages during build.
Original Workaround
One can make the linking to libiconv explicit by adding the following line to the haven/src/Makevars source file
PKG_LIBS=-liconv
which then let's you install from source R CMD INSTALL haven. However, editing packages feels hacky, plus this is something that will need to be done every upgrade, which sounds like a hassle.
Cleaner Workaround
Another option is to use withr::with_makevars, which allows one to temporarily control Makevars content. With this technique, one can install directly from the repo:
withr::with_makevars(c(PKG_LIBS="-liconv"), install.packages("haven"), assignment="+=")
